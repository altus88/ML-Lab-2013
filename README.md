2013-DL-GennadyShabanov
=======================
Code contains the following implementations:

•	Multinomial logistic regression implementation. Evaluation of the implementation on MNIST data. Visualization of the 10 receptive fields. Plot of the error curves for the training, evaluation and test set. 
•	Implementation of a neural network with one hidden layer. Minibatch gradient descent training and rmsprop. Evaluation of the implementation on MNIST. Visualization of the receptive fields of the first hidden layer, plots of the error curves. Numerical gradient check. 
•	Implementation of PCA and sparse Autoencoder (http://ufldl.stanford.edu/wiki/index.php/Autoencoders_and_Sparsity). PCA scatterplot (http://peekaboo-vision.blogspot.de/2012/12/another-look-at-mnist.html) on MNIST, and on CIFAR-10 (http://www.cs.toronto.edu/~kriz/cifar.html). Visualization of the learnt filters. 
•	Running t-SNE using the new Barnes-Hut implementation (http://homepage.tudelft.nl/19j49/t-SNE_files/bh_tsne.tar.gz) which allows to produce 2D embedding’s for a large number of samples. 
•	Implementation of K-Means. Implementation of steps on page 5 in the paper http://www.stanford.edu/~acoates/papers/coatesng_nntot2012.pdf. Visualization of the filters on CIFAR-10 (rescaled images from 32x32 to 12x12 pixels). Implementation of minibatch K-Means. 


